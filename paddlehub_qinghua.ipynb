{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paddlehub-qinghua.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfUoFAfNQJDBVqeI92qmte",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alg-bug-engineer/colab_models/blob/main/paddlehub_qinghua.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install paddlehub --upgrade -i https://mirror.baidu.com/pypi/simple \n",
        "!pip install paddlepaddle --upgrade -i https://mirror.baidu.com/pypi/simple "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh_yN-Em_kyL",
        "outputId": "75aff63e-d33c-42a1-acfc-0d7afdac783f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
            "Collecting paddlepaddle\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/b9/e9/baf17c5c450de7a6f0c4d7661ceeed2dc7d098370bc29c4f348b2c49b645/paddlepaddle-2.2.1-cp37-cp37m-manylinux1_x86_64.whl (108.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 108.4 MB 34 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (3.17.3)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (1.24.3)\n",
            "Installing collected packages: paddlepaddle\n",
            "Successfully installed paddlepaddle-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 第一次运行需要下载 ernie 模型，超级慢，看网络\n",
        "# 命令行一键情话生成\n",
        "!hub run ernie_gen_lover_words --input_text=\"七夕\" --use_gpu False --beam_width 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUqpb6kG_r3N",
        "outputId": "b3efe234-7ff2-4a2b-9042-2b2811a99922"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddlenlp/transformers/funnel/modeling.py:31: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "Download https://bj.bcebos.com/paddlehub/paddlehub_dev/ernie_gen_lover_words.tar.gz\n",
            "[##################################################] 100.00%\n",
            "Decompress /root/.paddlehub/tmp/tmp5b0t4rnw/ernie_gen_lover_words.tar.gz\n",
            "[##################################################] 100.00%\n",
            "\u001b[32m[2022-01-18 07:09:28,321] [    INFO]\u001b[0m - Successfully installed ernie_gen_lover_words-1.1.0\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:09:28,514] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie/ernie_v1_chn_base.pdparams and saved to /root/.paddlenlp/models/ernie-1.0\u001b[0m\n",
            "100% 392507/392507 [00:56<00:00, 7005.00it/s] \n",
            "\u001b[35m[2022-01-18 07:10:26,074] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:30,335] [    INFO]\u001b[0m - loading pretrained model from /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:31,102] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:31,102] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:31,102] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:31,102] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:31,102] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:35,762] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie/vocab.txt and saved to /root/.paddlenlp/models/ernie-1.0\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:10:35,762] [    INFO]\u001b[0m - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie/vocab.txt\u001b[0m\n",
            "100% 89.5k/89.5k [00:01<00:00, 58.8kB/s]\n",
            "[['七夕，想牵着你的手，唱着爱的歌谣，顺着幸福轨道，抛弃忧伤烦恼，望着星空祈祷，愿和你幸福到老。亲爱的，七夕情人节快乐!', '七夕，几许相思泪;七夕，佳人心相随;七夕，天地唱团圆，七夕，爱情是最美，祝天下有情之人把手牵，无情之人早坠情网!七夕节快乐!', '七夕，牛郎织女终于相见。牛郎:亲，俺想你!织女怒道:都一年没见了，你就不能和我多说点话吗?牛郎:亲，一年不见，你胖了，但是俺还是想你!', '七夕，几许相思泪;七夕，佳人心相随;七夕，天地唱团圆，七夕，爱情是最美，祝天下有情之人把手牵，无情之人早坠情网!七夕快乐!', '七夕，几许相思泪;七夕，佳人心相随;七夕，天地唱团圆，七夕，爱情是最美，祝天下有情之人把手牵，无情之人早坠情网!']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 命令行一键对联生成\n",
        "!hub run ernie_gen_couplet --input_text=\"终生伴侣何必门当户对\" --use_gpu False --beam_width 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaVtAW_Y_weS",
        "outputId": "561e81ce-642b-4632-c8e0-6ecd9ad4066d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddlenlp/transformers/funnel/modeling.py:31: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "Download https://bj.bcebos.com/paddlehub/paddlehub_dev/ernie_gen_couplet.tar.gz\n",
            "[##################################################] 100.00%\n",
            "Decompress /root/.paddlehub/tmp/tmpbwq50my_/ernie_gen_couplet.tar.gz\n",
            "[##################################################] 100.00%\n",
            "\u001b[32m[2022-01-18 07:38:45,484] [    INFO]\u001b[0m - Successfully installed ernie_gen_couplet-1.1.0\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:45,679] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[35m[2022-01-18 07:38:45,680] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:53,653] [    INFO]\u001b[0m - loading pretrained model from /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:54,590] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:54,590] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:54,590] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:54,590] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:54,590] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:38:59,344] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n",
            "[['一世姻缘只求道合志同', '一世姻缘只求夫唱妇随', '一世姻缘但求道合志同', '一世情缘只求道合志同', '百年姻缘只求道合志同']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 命令行一键诗歌生成\n",
        "!hub run ernie_gen_poetry --input_text=\"两情若是长久时，又岂在朝朝暮暮。\" --use_gpu False --beam_width 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzEEpWel_z2d",
        "outputId": "e5ce7b91-dd06-4c38-b689-c84f8bcccca2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddlenlp/transformers/funnel/modeling.py:31: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "Download https://bj.bcebos.com/paddlehub/paddlehub_dev/ernie_gen_poetry.tar.gz\n",
            "[##################################################] 100.00%\n",
            "Decompress /root/.paddlehub/tmp/tmpv0ufgwnm/ernie_gen_poetry.tar.gz\n",
            "[##################################################] 100.00%\n",
            "\u001b[32m[2022-01-18 07:41:13,547] [    INFO]\u001b[0m - Successfully installed ernie_gen_poetry-1.1.0\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:13,754] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[35m[2022-01-18 07:41:13,754] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:18,104] [    INFO]\u001b[0m - loading pretrained model from /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:18,982] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:18,982] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:18,983] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:18,983] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:18,983] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:41:23,546] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n",
            "[['欲知千里万里情，只在当初相见处。', '欲知千里万里情，只在当初相逢处。', '欲知千里万里情，只在当初相忆处。', '欲知千里万里情，须向月中看白兔。', '欲知千里与万里，一日之间有千虑。']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import paddlehub as hub\n",
        "# 参数\n",
        "\n",
        "# texts (list[str]): 情话的开头；\n",
        "# use_gpu (bool): 是否使用 GPU；若使用GPU，请先设置CUDA_VISIBLE_DEVICES环境变量；\n",
        "# beam_width: beam search宽度，决定每个情话开头输出的下文数目。\n",
        "# 返回\n",
        "\n",
        "# results (list[list][str]): 情话下文，每个情话开头会生成beam_width个下文。\n",
        "module = hub.Module(name=\"ernie_gen_lover_words\")\n",
        "\n",
        "test_texts = ['情人节']\n",
        "# 调用预测接口生成情话内容\n",
        "results = module.generate(texts=test_texts, use_gpu=False, beam_width=5)\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jpgp4eW_3qp",
        "outputId": "16d6abc2-d9a3-4e1c-8bb5-959501f1489c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddlenlp/transformers/funnel/modeling.py:31: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "\u001b[32m[2022-01-18 07:11:52,324] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[35m[2022-01-18 07:11:52,326] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:11:57,139] [    INFO]\u001b[0m - loading pretrained model from /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:11:58,733] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:11:58,742] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:11:58,751] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:11:58,753] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:11:58,758] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:12:03,583] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['情人节，我愿做一条鱼，任你红烧、白煮、清蒸，然后躺在你温柔的胃里。', '情人节，对你的思念太重，压断了电话线，烧坏了手机卡，掏尽了钱包袋，吃光了安眠药，哎!可我还是思念你。', '情人节，对你的思念太重，压断了电话线，烧坏了手机卡，掏尽了钱包袋，吃光了安眠药，哎!可我还是思念你，祝你情人节快乐!', '情人节，对你的思念太重，压断了电话线，烧坏了手机卡，掏尽了钱包袋，吃光了安眠药，唉!可我还是思念你，祝你情人节快乐!', '情人节，对你的思念太重，压断了电话线，烧坏了手机卡，掏尽了钱包袋，吃光了安眠药，哎!可是我还是思念你。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 在模型定义时，可以通过设置line=4或8指定输出绝句或律诗，设置word=5或7指定输出五言或七言。\n",
        "# 默认line=4, word=7 即输出七言绝句。\n",
        "module = hub.Module(name=\"ernie_gen_acrostic_poetry\", line=4, word=7)\n",
        "# 参数\n",
        "\n",
        "# texts (list[str]): 诗歌的藏头；\n",
        "# use_gpu (bool): 是否使用 GPU；若使用GPU，请先设置CUDA_VISIBLE_DEVICES环境变量；\n",
        "# beam_width: beam search宽度，决定每个藏头输出的下文数目。\n",
        "# 返回\n",
        "\n",
        "# results (list[list][str]): 诗歌下文，每个诗歌藏头会生成beam_width个下文。\n",
        "test_texts = ['七夕锁']\n",
        "# 调用预测接口生成藏头诗内容\n",
        "results = module.generate(texts=test_texts, use_gpu=False, beam_width=5)\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HadM1gEJANDL",
        "outputId": "a6fb4d68-99c4-44eb-e965-669ec28effed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download https://bj.bcebos.com/paddlehub/paddlehub_dev/ernie_gen_acrostic_poetry.tar.gz\n",
            "[##################################################] 100.00%\n",
            "Decompress /root/.paddlehub/tmp/tmpndrvjjhm/ernie_gen_acrostic_poetry.tar.gz\n",
            "[##################################################] 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2022-01-18 07:29:46,464] [    INFO]\u001b[0m - Successfully installed ernie_gen_acrostic_poetry-1.1.0\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:46,980] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[35m[2022-01-18 07:29:46,982] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:51,358] [    INFO]\u001b[0m - loading pretrained model from /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:53,305] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:53,307] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:53,308] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:53,316] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:53,320] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 07:29:57,996] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['七夕庭中罗绮干，夕阳还照客衣寒。锁门永夜无灯火，独倚栏干看月看。', '七夕庭中罗绮干，夕阳还照客衣寒。锁门永夜无人见，独倚栏干看月看。', '七夕庭中罗绮干，夕阳还照客衣寒。锁门永夜无灯火，独倚栏干看月寒。', '七夕庭中罗绮干，夕阳还照客衣寒。锁门永夜无灯火，独倚栏杆看月看。', '七夕庭中罗绮干，夕阳还照客衣寒。锁门永夜无人见，独倚栏干看月丹。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module = hub.Module(name=\"ernie_gen_couplet\")\n",
        "# 参数\n",
        "\n",
        "# texts (list[str]): 上联文本；\n",
        "# use_gpu (bool): 是否使用 GPU；若使用GPU，请先设置CUDA_VISIBLE_DEVICES环境变量；\n",
        "# beam_width: beam search宽度，决定每个上联输出的下联数量。\n",
        "# 返回\n",
        "\n",
        "# results (list[list][str]): 下联文本，每个上联会生成beam_width个下联。\n",
        "test_texts = [\"终身伴侣何必门当户对\", \"栏外红梅竞放\"]\n",
        "# 调用预测接口生成对联内容\n",
        "results = module.generate(texts=test_texts, use_gpu=False, beam_width=5)\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDUc7zs-AWaX",
        "outputId": "1d8a7006-0a19-49b5-ce8e-7e6ed8f23809"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2022-01-18 08:02:37,134] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[35m[2022-01-18 08:02:37,136] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:02:42,026] [    INFO]\u001b[0m - loading pretrained model from /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:02:44,947] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:02:44,950] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:02:44,952] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:02:44,954] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:02:44,956] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:02:53,688] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['一世姻缘只求道合志同', '一世姻缘只求夫唱妇随', '一生姻缘只求道合志同', '一世姻缘但求道合志同', '恩爱夫妻只求道合志同']\n",
            "['檐前紫燕双飞', '堂前紫燕双飞', '窗前紫燕双飞', '门前绿柳争春', '檐前紫燕争飞']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module = hub.Module(name=\"ernie_gen_poetry\")\n",
        "# 参数\n",
        "\n",
        "# texts (list[str]): 诗歌的开头；\n",
        "# use_gpu (bool): 是否使用 GPU；若使用GPU，请先设置CUDA_VISIBLE_DEVICES环境变量；\n",
        "# beam_width: beam search宽度，决定每个诗歌开头输出的下文数目。\n",
        "# 返回\n",
        "\n",
        "# results (list[list][str]): 诗歌下文，每个诗歌开头会生成beam_width个下文。\n",
        "test_texts = ['相见时难别亦难，东风无力百花残。', '两情若是长久时，又岂在朝朝暮暮。']\n",
        "# 调用预测接口生成诗歌内容\n",
        "results = module.generate(texts=test_texts, use_gpu=False, beam_width=5)\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm44hKNkAean",
        "outputId": "7ef591f2-3dd2-4ddd-8471-3538aeab181b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2022-01-18 08:03:09,286] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[35m[2022-01-18 08:03:09,287] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:03:13,371] [    INFO]\u001b[0m - loading pretrained model from /root/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:03:14,024] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:03:14,026] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:03:14,028] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:03:14,033] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:03:14,037] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
            "\u001b[32m[2022-01-18 08:03:19,677] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['可怜春色无人管，独倚阑干独凭栏。', '可怜春色无人管，独倚阑干独自看。', '可怜春色归何处，只有杨花拂面寒。', '可怜春色归何处，只有杨花满院寒。', '可怜春色无人管，独倚阑干独凭阑。']\n",
            "['欲知千里万里情，只在当初相见处。', '欲知千里万里情，只在当初相逢处。', '欲知千里万里情，只在当初相忆处。', '欲知千里万里情，须向月中看白兔。', '欲知千里与万里，一日之间有千虑。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 模型部署本地，进行调用\n",
        "!nohup hub serving start -m ernie_gen_lover_words -p 8866 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjv5bSWZAmeF",
        "outputId": "288d11c6-d8e3-4174-d221-c9f1cdf8d162"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# 配置好服务端，以下数行代码即可实现发送预测请求，获取预测结果\n",
        "\n",
        "data = {'texts':['情人节', '七夕', '小编带大家了解一下程序员情人节'],\n",
        "        'use_gpu':False, 'beam_width':5}\n",
        "headers = {\"Content-type\": \"application/json\"}\n",
        "url = \"http://127.0.0.1:8866/predict/ernie_gen_lover_words\"\n",
        "r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
        "\n",
        "# 保存结果\n",
        "results = r.json()[\"results\"]\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "jYV8PAT5ApS-",
        "outputId": "78bd6a0e-b237-4559-fce4-a20a9296c42b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f88a8e4a590>: Failed to establish a new connection: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8866): Max retries exceeded with url: /predict/ernie_gen_lover_words (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a8e4a590>: Failed to establish a new connection: [Errno 111] Connection refused'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-279a9cc3c1cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://127.0.0.1:8866/predict/ernie_gen_lover_words\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 保存结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8866): Max retries exceeded with url: /predict/ernie_gen_lover_words (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a8e4a590>: Failed to establish a new connection: [Errno 111] Connection refused'))"
          ]
        }
      ]
    }
  ]
}